{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Tidy Spatial Data in R - Student Version\"\n",
    "author: \"Sheila Saia & Ashton Drew\"\n",
    "date: \"October 4, 2019\"\n",
    "output:\n",
    "  word_document: default\n",
    "  html_document: default\n",
    "  pdf_document: default\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "# 1. INTRODUCTION\n",
    "\n",
    "This document provides an outline for class notes and code. I'll give the coding answers at the end of class, so you'll be sure to have working copies for future reference.\n",
    "\n",
    "### 1.1 Learning Outcomes\n",
    "\n",
    "By the end of this lesson you will be able to:\n",
    "\n",
    "1. *Describe* what the sf package is and how to use it\n",
    "2. *Explain* some different types of spatial sf objects and operations\n",
    "3. *Apply* sf and tidyverse operations to real-world geospatial data\n",
    "\n",
    "### 1.2 Test Setup\n",
    "\n",
    "You'll be using RStudio to do coding in R. Hopefully, you have current (less than 1 year old) versions of R and RStudio installed. Please check!\n",
    "\n",
    "If not, please [update R](https://cran.rediris.es/), [update RStudio](https://rstudio.com/products/rstudio/download/#download), and check for R package updates by going to Tools > Check for package updates... in RStudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version$version.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load Libraries\n",
    "\n",
    "Go ahead and load up the primary packages for today's lesson.  You'll need the tidyverse packages readr, dplyr, tidyr, and ggplot2. For working with spatial data, make sure you have sf and ggmap. Code to check and force install these packages is not included here, so you'll need to do this yourself before this code will run or knit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some tidyverse packages\n",
    "library(\"readr\")\n",
    "library(\"dplyr\")\n",
    "library(\"tidyr\")\n",
    "library(\"ggplot2\")\n",
    "library(\"purrr\")\n",
    "# some spatial data packages\n",
    "library(\"sf\")\n",
    "library(\"ggmap\")\n",
    "# some other packages\n",
    "library(\"here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure that the pdf() command works on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf(here(\"outputs\", \"pdf_test.pdf\"), width = 11, height = 8.5)\n",
    "ggplot(data = cars) +\n",
    "  geom_point(aes(x = dist, y = speed))\n",
    "dev.off()\n",
    "# it's ok to get a \"null device\" warning here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look in your your outputs folder. You should have a file called \"pdf_test.pdf\" that you can open up and looks ok. If not, you'll need to ask for help.\n",
    "\n",
    "**Activity**\n",
    "\n",
    "Let's go on a short reproductible research asside. The here package is very helpful for reproducible research. Rather than setting your working directory you can use R projects and here to make sure that paths to files work for anyone, regardless of your operating system. Try using the here::here() command to print out a data path for some data file you have.\n",
    "\n",
    "For expert advise/pleading on why you should use R projects and the here package see [this Twitter storm originating blogpost ](https://twitter.com/jennybryan/status/940436177219338240?lang=en) by Jenny Bryan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out here\n",
    "here()\n",
    "# if you've opened this script like I suggested your output should look something like\n",
    "# for mac: [1] \"/User/.../sf-lesson\"\n",
    "# for windows: [1] \"C:\\\\...\\sf-lesson\"\n",
    "\n",
    "# use here to generate a data path\n",
    "# here(\"directory1\", \"directory2\", \"...\", \"file.extension\")\n",
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 What is Geospatial Data?\n",
    "\n",
    "Geospatial data refers to any data that is associated with a location on Earth (or another planet). Usually this means that the data has coordinates (i.e., latitude and longitude or easting and northing).\n",
    "\n",
    "Types of geospatial data:\n",
    "\n",
    "1. points - a single coordinate combination of x and y (or longitude and latitude, respectively)\n",
    "2. lines - 2 or more points form a line\n",
    "3. polygons - 2 or more lines form a polygon\n",
    "\n",
    "Here's an example spatial data figure that you could make in R.\n",
    "\n",
    "![Figure 1. (a) Map of North Carolina with watersheds (grey polygons) and stream gages (black dots). (b) Map of North Carolina with basemap, overlapping watersheds (grey polygons) and overlapping stream gages (black dots).](img/figure1.png)\n",
    "\n",
    "**Activity**\n",
    "\n",
    "Can you think of examples of point, line, and polygon data in your field?\n",
    "\n",
    "### 1.5 Two Major Types of Spatial Data\n",
    "\n",
    "There are two main types of geospatial data:\n",
    "\n",
    "1. vector data - points, lines, polygons\n",
    "2. raster data - pixels (grid) where each grid cell represents a single attribute value\n",
    "\n",
    "Can you think of examples of vector and raster data in your field?\n",
    "\n",
    "What are some example file extensions for vector and raster data (spatial and non-spatial)?\n",
    "\n",
    "### 1.6 The Tidyverse and Spatial Data\n",
    "\n",
    "As of November 2019, there are two major spatial data R packages that interface well with the tidyverse. These are the sf and stars packages. We'll focus primarily on the sf package in this lesson because it works well with the tidyverse. I offer a number of links at the end of this document for you to learn more about other spatial data analysis packages for R.\n",
    "\n",
    "#### 1.6.1 sp (A Bit of History)\n",
    "\n",
    "The *sp* package is the first iteration of an R package created to handle vector spatial data. Given the likelihood that you'll come across old code, it's helpful to be familiar with both the older sp package and it's newer version, the sf package.\n",
    "\n",
    "**Things to Know About sp:**\n",
    "\n",
    "* Developed in 2005\n",
    "* Special objects of class SpatialData (an S4 datatype)\n",
    "* Composed of lists in lists (i.e., nested lists)\n",
    "* Attributes and spatial data are accessed using the @ symbol\n",
    "* Not always easy to manipulate the data because not the same as a regular data frame\n",
    "* When performing geographic operations, data often change class and sometimes loose their data\n",
    "\n",
    "#### 1.6.2 sf\n",
    "\n",
    "The *sf* package will generally operate faster and seamlessly within the tidyverse compared to the sp package, but is still in (rapid) development. Fortunately, it is very easy to move between sf and sp. You can read more about sf [here](https://github.com/r-spatial/sf).\n",
    "\n",
    "**Things to Know About sf:**\n",
    "\n",
    "* New in 2016 and growing rapidly\n",
    "* Regular data frames with an extra list-structured geometry column that are **not** SpatialData objects but are one of three nested main sf object classes (see below) represented by S3 datatypes\n",
    "* \"Language independent\" standard spatial data structure (ISO standard ISO 19125-1:2004: [https://www.iso.org/standard/40114.html](https://www.iso.org/standard/40114.html))\n",
    "* Follow tidy data rules and will not change class (though geometry can change) and retain their data\n",
    "* Tidyverse commands that work with sf objects: [https://r-spatial.github.io/sf/reference/tidyverse.html](https://r-spatial.github.io/sf/reference/tidyverse.html)\n",
    "* Use spatial indexing, so many spatial query operations faster\n",
    "* Cannot be used in operations that require data of class SpatialData (i.e., sp objects)\n",
    "\n",
    "Sf objects are organized into three main classes, which you can read more about [here](https://r-spatial.github.io/sf/articles/sf1.html). In most cases these classes are nested. That is, an sf object contains an sfc object which contains a sfg object (see full description below). It is possible to convert back and forth between these summary classes using functions like st_as_sf() and st_as_sfc(). I'll discuss this more in Sections 2.6 and 2.7. \n",
    "\n",
    "**Main sf Geometry Classes:**\n",
    "\n",
    "Also, sf geometries are organized into three main classes:\n",
    "\n",
    "1. sf - the data frame that with feature attributes and feature geometries, this contains...\n",
    "2. sfc - the list-column with the geometries for each record, this contains...\n",
    "3. sfg - the feature geometry of an individual simple feature\n",
    "\n",
    "There are a number of different types of \"simple features\" geometry types represented by the sf package (Table 1). You can read about all of these [here](https://r-spatial.github.io/sf/articles/sf1.html).\n",
    "\n",
    "![Table 1. Geometries represented in the sf package. Source: https://r-spatial.github.io/sf/articles/sf1.html](img/sf_geometries.png)\n",
    "\n",
    "#### 1.6.3 stars\n",
    "\n",
    "The stars package is used for handling raster and vector data. Its name stands for \"spatio-temporal tidy arrays for R\". You can read more about stars [here](https://github.com/r-spatial/stars).\n",
    "\n",
    "Two caveats here are that (1) stars is still being developed and (2) it is built to be used for multi-dimensional *vector and raster* data (e.g., a 10-year long time-series of rainfall grids for the USA) called \"arrays\" or \"data cubes\". There is also the raster package, which is used for raster data only, but it does not interface well with the tidyverse. You can read more about the raster package [here](https://github.com/rspatial/raster). The mapedit package might be of interest if you're looking to edit spatial data (e.g., snapping GPS points to streams or roads). For more info on mapedit go [here](https://github.com/r-spatial/mapedit). Check out the [rspatial GitHub page](https://github.com/r-spatial) for the latest updates on all these R packages.\n",
    "\n",
    "### 1.7 What is a coordinate reference system (CRS)?\n",
    "\n",
    "A coordinate reference systems defines how we convert (or we can say \"project\") a 3D object (in this case, the Earth) to 2D surface.\n",
    "\n",
    "There are three major types of projections:\n",
    "\n",
    "1. cylindrical\n",
    "2. conical\n",
    "3. planar\n",
    "\n",
    "This image shows what I mean by \"project\".\n",
    "\n",
    "![Figure 2. Depiction of different spatial projections. Source: https://docs.qgis.org/](img/projections.png)\n",
    "\n",
    "Each projection type preserves unique spatial properties. You should choose the projection you use based on what spatial property (i.e., distance, area, angle) you want to preserve. For more on this see [here](https://docs.qgis.org/testing/en/docs/gentle_gis_introduction/coordinate_reference_systems.html#figure-projection-families).\n",
    "\n",
    "You might have also heard the word \"datum\". Some example datums include WGS84 or NAD83. A datum is the reference surface (usually an spheroid) that anchors a CRS. The WGS84 datum is a 3D reference surface (usually in latitude and longitude) while NAD83 is a 2D (projected) reference surface (usually in distance units like meters).\n",
    "\n",
    "Figure 3 shows how a datum defines a spheroid that forms the reference surface for real-world spatial data. This data can then be projected onto a 2D surface (i.e., a map).\n",
    "\n",
    "![Figure 3. Schematic of how we represent 3D information on a 2D surface. Source: https://gis.stackexchange.com/](img/datum.png)\n",
    "\n",
    "#### 1.7.1 An !Important! Note About Coordinate Reference Systems (CRSs)\n",
    "\n",
    "**R does not manage CRS \"on the fly\"**, so the onus is on you to manage the CRS (and extent, resolution, etc.) of your data. Many times this will mean that when attempting to work with two or more data (e.g., extract values to points from a set of shape files), you will get an error message that the data do not share projects and/or they do not align. Often you can also not get an error message but your data might not be showing up on your map correctly (e.g., spatial boundaries are not lining up).\n",
    "\n",
    "I find CRS management to be one of the time consuming parts of spatial data work in R. At the start of any spatial data project, you may wish to establish a set of reference data objects (e.g., snapshp.shp) to serve as a template for the official projection, extent, origin, resolution, etc.  When you import any data to R, you should always check if it matches snapshp.shp and, if not, proceed to reproject, crop, clip, resample, alignâ€¦. Whatever steps are necessary to make it conform to the project template.\n",
    "\n",
    "#### 1.7.2 CRS Representation in sf\n",
    "\n",
    "There are two main ways to define a CRS in sf:\n",
    "\n",
    "1. proj4 string - a character string with CRS info\n",
    "2. EPSG code - a standard numeric code that defines a projection type\n",
    "\n",
    "As long as one of these is defined, you can move on. However, if you want to define both, that might prove less confusing to your future-self. :)\n",
    "\n",
    "#### 1.7.3 Coordinate Systems Websites\n",
    "\n",
    "Various websites provide free services to look-up CRS definitions, characteristics, and transformations\n",
    "\n",
    "Most provide one or more of the following: \n",
    "\n",
    "* a short permanent link\n",
    "* opportunity to export CRS definition in various formats (WKT, XML, OGC GML, Proj.4, JavaScript, SQL)\n",
    "* a numeric reference code (i.e., EPSG code) that can be used in place of a fully specified CRS\n",
    "\n",
    "Some suggested websites:\n",
    "\n",
    "1. [https://epsg.io/](http://www.epsg-registry.org/) - open source nicer user interface to access data in the EPSG registry, includes a little transformation calculator too! and proj4 string generator, this is my go-to CRS look-up database\n",
    "2. [https://spatialreference.org/ref/epsg/](https://spatialreference.org/ref/epsg/)\n",
    "3. [http://www.epsg-registry.org/](http://www.epsg-registry.org/) - official database, but ugly slow interface\n",
    "\n",
    "#### 1.7.4 Common CRS for US & European Data\n",
    "\n",
    "**EPSG:4326**\n",
    "\n",
    "WGS 84 or WGS84 (World Geodetic System 1984, used in GPS)\n",
    "[http://epsg.io/4326](http://epsg.io/4326)\n",
    "\n",
    "**EPSG:54024**\n",
    "\n",
    "ED50 (European Datum 1950, used in EU GPS)\n",
    "[http://epsg.io/54024](http://epsg.io/54024)\n",
    "\n",
    "**EPSG:102013**\n",
    "\n",
    "NAD83 / Europe Albers Equal Area Conic\n",
    "[http://epsg.io/102013](http://epsg.io/102013)\n",
    "\n",
    "**EPSG:various UTM**\n",
    "\n",
    "Universal Transverse Mercator (UTM)\n",
    "You need to find your UTM zone and then determine EPSG from there. To look up your zone go to [this website](https://mangomap.com/robertyoung/maps/69585/what-utm-zone-am-i-in-#).\n",
    "\n",
    "**EPSG:102014**\n",
    "\n",
    "ED50 / Europe Lambert Conformal Conic\n",
    "[http://epsg.io/102014](http://epsg.io/102014)\n",
    "\n",
    "**EPSG:54024**\n",
    "\n",
    "WGS84 / World Bonne\n",
    "[http://epsg.io/54024](http://epsg.io/54024)\n",
    "\n",
    "#### 1.7.5 A Quick Reference for CRSs in R\n",
    "\n",
    "National Center for Ecological Analysis and Synthesis created a CRS summary sheet.  Useful quick reference as well as background if you don't have much knowledge of all the various choices presented.\n",
    "\n",
    "[https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/OverviewCoordinateReferenceSystems.pdf](https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/OverviewCoordinateReferenceSystems.pdf)\n",
    "\n",
    "# 2. READING IN DATA\n",
    "\n",
    "### 2.1 Data Background\n",
    "\n",
    "The data we'll use in this lesson comes from the United States Geologic Survey (USGS). Specifically, the dataset is called the Geospatial Attributes of Gages for Evaluating Steamflow, version 2 (GAGES-II) available [here](https://water.usgs.gov/GIS/metadata/usgswrd/XML/gagesII_Sept2011.xml). GAGES-II provides geospatial data and classifications of 9,322 stream gages that are maintained by the USGS. It includes: (1) watershed boundaries by region (spatial data), (2) USGS stream gage locations (spatial data), (3) watershed characteristics (tabular data). Note that the term \"watershed\" is used interchangeably with the word \"basin\".\n",
    "\n",
    "We'll also being using Southeast state boundary data from the United States Census Bureau.\n",
    "\n",
    "Here is what the spatial data for this lesson looks like (Figure 4). Southeast state boundaries are shown in dark green, watershed boundaries are shown in light green, and stream gage locations are shown as grey points.\n",
    "\n",
    "![Figure 4. Data used in this lesson.](img/gagesii.png)\n",
    "\n",
    "### 2.2 Loading in the Data\n",
    "\n",
    "Start by reading in the basin boundaries for non-reference (i.e., notable human impact) for the Southeast Plains using `st_read()` from the sf package. Notice how you only call the .shp file here. You don't need to include all the other files that come along with the .shp file (i.e., .prj, .sbn, .shx, .sbx, .dbf, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basins_nf_seplains_raw <- st_read(here(\"data\", \"spatial_data\", \"bas_nonref_SEPlains.shp\"))\n",
    "# note how I'm using the here package!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity**\n",
    "\n",
    "Now you practice loading in:\n",
    "\n",
    "1. GAGES-II stream gage points (gagesII_9322_sept30_2011). Name these data \"gages_raw\".\n",
    "2. The boundary lines of US states (southeast_state_bounds). Name these data \"southeast_state_bounds_raw\".\n",
    "3. One of the GAGES-II tabular data. Hint: Think back to other classes for this one. Also see the README.md file in the tabular data folder for a full description of each GAGES-II tabular data file.\n",
    "\n",
    "I like to always save a copy of the raw data in my R session and rename all new variables I make from it with new names. That way, I can always look back to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete the code below\n",
    "gages_raw <- st_read(here(\"data\", \"spatial_data\", \"gagesII_9322_sept30_2011.shp\"))\n",
    "southeast_state_bounds_raw <- st_read(here(\"data\", \"spatial_data\", \"southeast_state_bounds.shp\"))\n",
    "my_tabular_data_raw <- read_csv(here(\"data\", \"tabular_data\", \"conterm_climate.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Familiarizing Ourselves with the Data\n",
    "\n",
    "Now that you've loaded in these data, take a look at their format, information included, etc.\n",
    "\n",
    "**Activity**\n",
    "\n",
    "Use base R commands to answer the following questions (for basins_nf_seplains_raw):\n",
    "\n",
    "1. What is the class?\n",
    "2. What are the names of each column? \n",
    "3. How many columns are there?\n",
    "4. What are the attributes?\n",
    "5. Show the first several lines of these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n",
    "class(basins_nf_seplains_raw)\n",
    "names(basins_nf_seplains_raw)\n",
    "length(names(basins_nf_seplains_raw))\n",
    "head(basins_nf_seplains_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not in base, you can also use glimpse() from the tibble (tidyverse) package to look at basin_nf_seplains_raw.\n",
    "\n",
    "With respect to question 5th above, you might notice some interesting outputs that aren't usually there: geometry type, dimension, bbox, EPSG, and proj4string. There are included there because basins_nf_seplains_raw is a spatial data. Some of these we've talked about before (i.e., EPSG and proj4string).\n",
    "\n",
    "The *geometry* columns is what defines the spatial aspect of these data and make it a sf object. If there were no geometry column basin_nf_seplains_raw would just be a data.frame or tibble.\n",
    "\n",
    "### 2.4 Checking CRSs\n",
    "\n",
    "The sf package contains the st_crs function which allows you to look at the CRS of your spatial data.\n",
    "\n",
    "**Activity**\n",
    "\n",
    "Use st_crs() to look at the CRSs of the spatial data you have loaded up so far. What are the CRSs for each? Do they all have complete EPSG or proj4 strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n",
    "st_crs(basins_nf_seplains_raw)\n",
    "st_crs(gages_raw)\n",
    "st_crs(southeast_state_bounds_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Setting and Projecting CRSs\n",
    "\n",
    "Now that you've checked the CRSs of your spatial data, you can either set or project them so they are compatible with one another. When *setting* a CRS, you're labeling the spatial data with a CRS it already has but is not showing up when you load the data into R. Setting also includes defining a missing ESPG or proj4 string; if one is complete but the other is not. When *projecting* a CRS, you're converting the spatial data from one CRS to another. For the sf package, transform is used interchangeably with project. It's important know the difference between setting and projecting!\n",
    "\n",
    "Set a CRS by:\n",
    "\n",
    "1. Defining proj4 string using st_crs(<data>) <- \"<known proj4string>\"\n",
    "2. Defining EPSG string using st_crs(<data>) <- <known ESPG code> or using st_set_crs(<known EPSG code>) in a pipe like new_data <- raw_data %>% st_set_crs(5070)\n",
    "\n",
    "Project a CRS by:\n",
    "\n",
    "1. Using st_transform(x = <data>, crs = <new CRS proj4 string>)\n",
    "\n",
    "I noticed if you tried to define proj4text inside st_crs() your data is converted to class CRS (not sf). The same thing happens if you set value to the proj4 string or EPSG code. I'm not sure why changing the data to a CRS object is the default. Also, sometimes its helpful to define your proj4 string or EPSG code as a variable like my_proj4 or my_epsg so you can use it throughout your code without having to change it every time.\n",
    "\n",
    "#### 2.5.1 A Note on Figuring Out CRS Information\n",
    "\n",
    "You can always use [espg.io](http://epsg.io/) for help or open up the spatial data in your favorite GIS software, if you really get stuck. For example, QGIS gives the ESPG code of spatial data in the lower right-hand corner (assuming it is defined). If it is not defined, you should visit the documentation associated with the spatial data for the CRS information.\n",
    "\n",
    "**Activity**\n",
    "\n",
    "All three datasets have the same projection but different some elements are missing. Use the commands above to define a new variable (remove \"raw\" from the end) representing each of the three spatial datasets with both a proj4 string and EPSG code representing the USGS's Continental United States Albers Equal Area Conic NAD83 (proj4 = \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\" and ESPG = 5070).\n",
    "\n",
    "Pick one of the three datasets, define a new variable with \"na_albers\" at the end, use the commands above to project it to North America Albers Equal Area Conic. Hint: You can use [espg.io](http://epsg.io/) for help.\n",
    "\n",
    "Last, check the CRSs of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define proj4 string and EPSG code\n",
    "# complete the code below\n",
    "my_proj4 <- \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"\n",
    "my_epsg <- 5070\n",
    "\n",
    "# setting projections\n",
    "# set the proj4 string first and then set the EPSG code (because proj4 will over-ride EPSG if you set EPSG first)\n",
    "# add your code here\n",
    "st_crs(basins_nf_seplains_raw) <- my_proj4\n",
    "\n",
    "basins_seplains <- st_set_crs(basins_nf_seplains_raw, crs = my_epsg)\n",
    "\n",
    "basin_seplains <- basins_nf_seplains_raw %>%\n",
    "  st_set_crs(my_epsg)\n",
    "\n",
    "# projecting to North America Albers Equal Area Conic\n",
    "# add your code here\n",
    "na_albers_proj4 <- \"+proj=aea +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m no_defs\"\n",
    "na_alber_epsg <- 102008\n",
    "\n",
    "# check CRSs\n",
    "basin_seplains_albers <- sf::st_transform(basin_seplains, crs = na_albers_proj4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Converting sp Objects to sf Objects and Vice Versa\n",
    "\n",
    "If you're using other (likely older) types of spatial data, R may not recognize them as sf objects. For example, a collaborator may give you some older code that uses the sp package to generate spatial data. First, make sure to double check the class using class(). If the object is not an sf object, you can use st_as_sf() or st_as_sfc() to convert your data to sf or sfc objects.\n",
    "\n",
    "Also, you can use the command as_Spatial() to convert sf objects back to sp SpatialData objects. This might be important for you if you're working with a collaborator that uses older sp package code.\n",
    "\n",
    "### 2.7 Converting From One sf Geometry Type to Another\n",
    "\n",
    "In some cases, you might want to convert (or \"cast\") from one geometry type to another. For a complete list of sf geometry types see Section 1.6.2 (Table 1). To cast from one sf geometry type to another you can use the st_cast() command. You have to explicitly define what type of geometry you want to cast to.\n",
    "\n",
    "### 2.8 Converting Tabular Data to Spatial Data\n",
    "\n",
    "What if you don't have a .shp file; instead, you have tabular data with spatial variables in columns? You're in luck! There are ways to convert tabular data to sf objects. \n",
    "\n",
    "Commands to convert tabular data to corresponding sf objects:\n",
    "\n",
    "1. st_point()\n",
    "2. st_multipoint()\n",
    "3. st_linestring()\n",
    "4. st_multilinestring()\n",
    "5. st_polygon()\n",
    "6. st_multipolygon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in GAGES-II data in tabular format\n",
    "gages_tabular <- read_csv(here(\"data\", \"tabular_data\", \"gagesII_sept30_2011_tabular.csv\")) %>%\n",
    "  as.data.frame() # use this to drop the tibble classes (i.e., tbl_df and tbl)\n",
    "\n",
    "# look at class\n",
    "class(gages_tabular)\n",
    "\n",
    "# use names() to get spatial data columns\n",
    "names(gages_tabular)\n",
    "# LAT_GAGE is y value and LNG_GAGE is x value\n",
    "\n",
    "# convert to sf object\n",
    "gages_tabular_as_sf <- st_as_sf(gages_tabular, coords = c(\"LNG_GAGE\", \"LAT_GAGE\"), crs = 4326, dim = \"XY\") # lat long so set CRS = WGS84\n",
    "\n",
    "# check class and CRS\n",
    "class(gages_tabular_as_sf)\n",
    "head(gages_tabular_as_sf)\n",
    "st_crs(gages_tabular_as_sf)\n",
    "\n",
    "# check by plotting (more on plotting below)\n",
    "pdf(here(\"outputs\", \"tabular_to_sf_check.pdf\"), width = 11, height = 8.5)\n",
    "ggplot() +\n",
    "  geom_sf(data = gages_tabular_as_sf) +\n",
    "  theme_bw()\n",
    "dev.off()\n",
    "# seems to work just fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like you can also manually make a \"geometry\" column using your standard tidyverse functions and use this to convert from a tabular data format to a sf format. See [this GitHub issue](https://github.com/r-spatial/sf/issues/385) for more information.\n",
    "\n",
    "# 3. USING THE DATA\n",
    "\n",
    "### 3.1 Spatial Data Operations\n",
    "\n",
    "There are numerous spatial operations, we can run on spatial data.\n",
    "\n",
    "**Activity**\n",
    "\n",
    "What are some things you might want to do with the three spatial datasets we have here? Brainstorm these with a partner and if you have time, look through the sf package help to see what types of commands you might use.\n",
    "\n",
    "For example, you might want to select a state from southeast_state_bounds and find it's area. You might want to find how many gages are inside that state.\n",
    "\n",
    "#### 3.1.1 A Note on Spatial Geometry\n",
    "\n",
    "In some cases, we might not necessarily need the tabular data associated with a spatial dataset. For example, say you decide that you just want to look at GAGES-II data in North Carolina. Once you have the boundary lines for North Carolina you might not need all the spatial data associate with it. You can remove the tabular data using the st_geometry() command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabular data is attached\n",
    "head(southeast_state_bounds)\n",
    "southeast_state_bounds_geometry <- st_geometry(southeast_state_bounds)\n",
    "\n",
    "# tabular data is dropped\n",
    "head(southeast_state_bounds_geometry)\n",
    "\n",
    "# notice the class is different now\n",
    "class(southeast_state_bounds_geometry)\n",
    "# it's an sfc class, specifically an sfc_MULTIPOLYGON class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other cases, you might just want to keep the tabular data (attributes) associated with spatial data. To remove geometry you can use the st_drop_geometry() command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geometry data is attached\n",
    "head(southeast_state_bounds)\n",
    "southeast_state_bounds_tabular <- st_drop_geometry(southeast_state_bounds)\n",
    "\n",
    "# geometry data is dropped\n",
    "head(southeast_state_bounds_tabular)\n",
    "\n",
    "# notice the class is different now\n",
    "class(southeast_state_bounds_tabular)\n",
    "# it's a data.frame class, we could convert to a tibble using as_tibble()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Common Spatial (Geometric/Geometry) \"Operations\"\n",
    "\n",
    "Some common sf spatial operation commands might include (in no special order):\n",
    "\n",
    "1. st_transform() - We've seen this before. Projects from one CRS to another.\n",
    "2. st_area() - Calculates the area of a polygon.\n",
    "3. st_centroid() - Finds the centroid (x-y coordinate) of a polygon or combined geometry.\n",
    "4. st_difference() - Removes overlapping spatial data between two datasets.\n",
    "5. st_intersection() - Finds overlapping spatial data between two datasets where output is an sf object that's clipped to the boundary of the intersected dataset.\n",
    "6. st_simplify() - Makes a simpler version of a geometry based on a given tolerance. This helps reduce file size and speed up visualization loading.\n",
    "7. st_snap() - Snaps points or nodes to a second spatial dataset.\n",
    "8. st_buffer() - Creates a polygon extending from a geometry within a given distance.\n",
    "9. st_boundary() - Finds a polygon that encompasses the full extent of the geometry.\n",
    "10. st_crop() - Makes a geometry that intersects a specified rectangle, where the rectangle can be the greatest rectangular boundary of the dataset provided\n",
    "11. so many others...\n",
    "\n",
    "I'm distinguishing these from Spatial (Geometric) \"Confirmations\" which are similar operations but the output is a list object rather than a sf object. For example, st_intersects() and st_within(). See the sf cheatsheet for more information on this.\n",
    "\n",
    "Also, sometimes the differences between these operations can be confusing/not obvious so what I tend to do is try them out and then plot the result to make sure it's doing what I think it's doing. If it's not, then you can trouble-shoot from there.\n",
    "\n",
    "**Activity**\n",
    "\n",
    "Use your knowledge of sf and the tidyverse to select a single state from southeast_state_bounds. Next, drop the geometry and use the state boundary to select watersheds and stream gages that intersect with the state.\n",
    "\n",
    "Bonus: What are some other spatial operations (or confirmations) that you could carry out with the three spatial datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a state\n",
    "florida <- southeast_state_bounds %>%\n",
    "  filter(NAME == \"Florida\")\n",
    "\n",
    "# check\n",
    "glimpse(florida)\n",
    "\n",
    "# select watersheds that intersect with NC bounds\n",
    "# add your code here\n",
    "\n",
    "# check\n",
    "# add your code here\n",
    "\n",
    "# select gages that fall within NC bounds\n",
    "fl_gages <- st_intersection(gages, florida)\n",
    "\n",
    "# remove attributes from fl boundary\n",
    "fl_geometry <- st_geometry(florida)\n",
    "\n",
    "# ggplot\n",
    "pdf(here(\"outputs\", \"florida_gages.pdf\"), width = 11, height = 8.5)\n",
    "ggplot() +\n",
    "  geom_sf(data = fl_geometry) +\n",
    "  geom_sf(data = fl_gages, aes(color = DRAIN_SQKM)) +\n",
    "  theme_bw()\n",
    "dev.off()\n",
    "\n",
    "\n",
    "# bonus\n",
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've found that it's really helpful to actually plot these results before moving forward with your work. That way you an make sure the sf commands are doing what you expect. We'll talk about plotting next...\n",
    "\n",
    "### 3.2 Visualizing Data\n",
    "\n",
    "#### 3.2.1 Viz Basics\n",
    "\n",
    "An import part of spatial data analysis is to *check your work* and also *share your results*. The sf package makes this very easy by adding a geom_sf() to add a vector data layer and geom_sf_text() to add a label layer to any ggplot2 object.\n",
    "\n",
    "Usually I use RStudio to visualize all of my plots but since spatial data often has a large file size, it can take a while to load in the built-in RStudio plotting window. Until the folks at RStudio and sf package developers deal with this, I recommend exporting your spatial visualizations to PDF files in a dedicated folder. Here, we'll practice exporting our plots to the \"outputs\" folder. Make sure you run all lines of code starting from pdf() to dev.off(). The pdf() will write and open a new empty PDF file and dev.off() will close it. It's ok to get a \"null device\" message here. R is just telling you that it closed the pdf file it created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic plot\n",
    "pdf(here(\"outputs\", \"southeast_state_bounds.pdf\"), width = 11, height = 8.5)\n",
    "ggplot() +\n",
    "  geom_sf(data = southeast_state_bounds) + # you can add color = \"blue\" to change outline color to blue or lwd = 2 to change the width of the lines\n",
    "  theme_bw() # I like to add this to make the background white and not grey\n",
    "dev.off()\n",
    "\n",
    "# adding labels\n",
    "pdf(here(\"outputs\", \"southeast_state_bounds_with_labs.pdf\"), width = 11, height = 8.5)\n",
    "ggplot(data = southeast_state_bounds) + # Notice I moved this up here so I don't have to keep calling it\n",
    "  geom_sf() +\n",
    "  geom_sf_text(aes(label = NAME), color = \"blue\") +\n",
    "  theme_bw()\n",
    "dev.off()\n",
    "\n",
    "# adding fill by a second variable\n",
    "pdf(here(\"outputs\", \"southeast_state_bounds_by_area.pdf\"), width = 11, height = 8.5)\n",
    "ggplot(data = southeast_state_bounds) +\n",
    "  geom_sf(aes(fill = Shape_Area)) +\n",
    "  geom_sf_text(aes(label = NAME), color = \"white\") +\n",
    "  theme_bw()\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity**\n",
    "\n",
    "Let's check your operations from the 3.1.2 activity. You are trying for something like Figure 1a. Are the spatial operation results working as you'd expect? Test out running other operations (i.e., st_crop() and st_contains()) and plotting them to better understand what those do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot watershed boundardies from 3.1.2\n",
    "pdf(here(\"outputs\", \"spatial_operations_test_fig\"), width = 11, height = 8.5)\n",
    "# add your code here\n",
    "\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a few things about Figure 1a: (1) the watersheds are nested (there are smaller ones inside bigger ones), (2) the larger watersheds are cut by the state boundaries, and (3) there are some gages that are outside the watershed bounds (i.e., we don't have watershed basins or tabular data for them).\n",
    "\n",
    "#### 3.2.2 Adding Base-Maps\n",
    "\n",
    "Basemaps are available to help you give more context to your maps. This is made possible using the ggmap package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select North Carolina (NC)\n",
    "nc_state_bounds_geom <- southeast_state_bounds %>%\n",
    "  filter(NAME == \"North Carolina\") %>%\n",
    "  st_geometry()\n",
    "# if I wanted Florida instead, what would I need to do?\n",
    "\n",
    "# get data bounding box\n",
    "nc_bbox <- nc_state_bounds_geom %>%\n",
    "  st_buffer(dist = 150000) %>% # this value is very arbitrary just wanting to make a large buffer around geometry\n",
    "  st_transform(4326) %>% # WGS84 (for lat and long)\n",
    "  st_bbox()\n",
    "nc_bbox # check\n",
    "\n",
    "# fix bounding box columns so they match what is needed for the ggmap::get_map() function\n",
    "nc_bbox_fix <- c(left = nc_bbox[[1]], bottom = nc_bbox[[2]], right = nc_bbox[[3]], top = nc_bbox[[4]])\n",
    "\n",
    "# check result\n",
    "nc_bbox_fix\n",
    "\n",
    "# get basemap\n",
    "nc_basemap <- get_map(nc_bbox_fix, maptype = 'terrain-background', source = 'stamen', zoom = 8)\n",
    "# this will have a CRS = WGS84\n",
    "\n",
    "# convert nc_state_bounds_geom to WGS84 so it matches nc_basemap\n",
    "nc_state_bounds_geom_wsg84 <- nc_state_bounds_geom %>%\n",
    "  st_transform(4326)\n",
    "\n",
    "# check\n",
    "st_crs(nc_state_bounds_geom_wsg84)\n",
    "\n",
    "# plot without basemap\n",
    "pdf(here(\"outputs\", \"nc_without_basemap.pdf\"), width = 11, height = 8.5)\n",
    "ggplot() +\n",
    "  geom_sf(data = nc_state_bounds_geom_wsg84, fill = NA, lwd = 2) +\n",
    "  theme_bw()\n",
    "dev.off()\n",
    "\n",
    "# plot with basemap\n",
    "# windows version?\n",
    "pdf(here(\"outputs\", \"nc_with_basemap.pdf\"), width = 11, height = 8.5)\n",
    "ggmap(nc_basemap) +\n",
    "  geom_sf(data = nc_state_bounds_geom_wsg84, fill = NA, lwd = 1, inherit.aes = FALSE)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity**\n",
    "\n",
    "Can you reproduce Figure 1b?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select NC\n",
    "# add your code here\n",
    "\n",
    "# make figure 1b\n",
    "# find watersheds that overlap with NC (want the whole watershed, not just the part of the watershe that's inside the NC bounds)\n",
    "# add your code here\n",
    "\n",
    "# look at result\n",
    "# add your code here\n",
    "\n",
    "# hint: make a function to convert binary to logic\n",
    "binary_logic_converter <- function (x) {\n",
    "  if (length(x) == 1) {\n",
    "    return(TRUE)\n",
    "  } else {\n",
    "    return(FALSE)\n",
    "  }\n",
    "}\n",
    "# source: http://rpubs.com/sogletr/sf-ops\n",
    "\n",
    "# map function on data and select only true values\n",
    "# add your code here\n",
    "\n",
    "# look at result\n",
    "# add your code here\n",
    "\n",
    "# use nc_basins_overlap_logic to select only watersheds that overlap\n",
    "# add your code here\n",
    "\n",
    "# check class\n",
    "# add your code here\n",
    "\n",
    "# select Southeast gages only\n",
    "# add your code here\n",
    "# stretch break...this might take a while to run\n",
    "\n",
    "# use nc_basins_overlap_sel to find gages inside\n",
    "# add your code here\n",
    "# stretch break...this might take a while to run\n",
    "\n",
    "# convert all data to WGS84\n",
    "# add your code here\n",
    "\n",
    "# plot figure 1b\n",
    "pdf(here(\"outputs\", \"figure_1b.pdf\"), width = 11, height = 8.5)\n",
    "# add your code here\n",
    "\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Mixing Spatial and Tabular Data\n",
    "\n",
    "The sf and tidyverse packages work together very well to wrangle spatial and tabular data. You may have noticed that some of the code above uses the pipe operator (i.e., %>%) to link together analysis steps. Some of the dplyr verbs will also work with sf objects See [here](https://r-spatial.github.io/sf/reference/tidyverse.html) for more info on these verbs.\n",
    "\n",
    "Let's try an example. Here we'll select all the gages in NC, join them with one of the GAGES-II tabular datasets, and create a map that colors these gage locations by a particular variable in the tabular dataset. We might want to do this as the start of spatial trend analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the NC state boundary we used earlier to select all the stream gages in NC\n",
    "nc_gages <- gages %>%\n",
    "  st_intersection(nc_state_bounds_geom)\n",
    "\n",
    "# take a look at ng_gages\n",
    "head(nc_gages)\n",
    "names(nc_gages)\n",
    "# we see there are some variables we could color by but the tabular data has many more\n",
    "\n",
    "# take a look at my_tabular_data_raw\n",
    "names(my_tabular_data_raw)\n",
    "# I'm choosing the climate data and am going to use the WD_SITE variable. This is the \"Site average of annual number of days (days) of measurable precipitation, derived from 30 years of record (1961-1990), 2km PRISM.\". This description comes from the gagesII_sept30_2011_var_desc.xlsx file in the tabular data directory.\n",
    "\n",
    "# check column names of nc_gages to look for joining key\n",
    "names(nc_gages)\n",
    "# use \"STAID\"\n",
    "\n",
    "# join the tabular data to nc_gages\n",
    "nc_gages_climate <- nc_gages %>%\n",
    "  left_join(my_tabular_data_raw, by = \"STAID\")\n",
    "\n",
    "# check that it worked\n",
    "names(nc_gages_climate)\n",
    "# looks good!\n",
    "\n",
    "# plot WD_SITE for each gage location\n",
    "pdf(here(\"outputs\", \"nc_gages_by_tabular_data.pdf\"), width = 11, height = 8.5)\n",
    "ggplot() +\n",
    "  geom_sf(data = nc_gages_climate, aes(color = WD_SITE), size = 3) +\n",
    "  scale_color_gradient(low = \"white\", high = \"blue\") +\n",
    "  labs(color = \"Gage Avg. Annual # Days with Precipitation\") +\n",
    "  geom_sf(data = nc_state_bounds_geom, fill = NA) +\n",
    "  theme_bw()\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have some emerging patterns in average number of days per year with precipitation at the stream gage. We'd have to do some spatial modeling to verify this. It's notable that the Appalachian Mountains are located in the western part of the state, which is where we see the highest number of days per year with precipitation.\n",
    "\n",
    "**Activity**\n",
    "\n",
    "Practice joining other types of tabular data onto the spatial datasets provided here. Hint: You can rename the the GAGE_ID column from the basins_nf_seplains dataset to STAID to join the tabular data to each basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use overlapping watersheds from 3.2.2 (or from 3.1.2 if you didn't do 3.2.2)\n",
    "# add your code here\n",
    "\n",
    "# join tabular data\n",
    "# add your code here\n",
    "\n",
    "# check result\n",
    "# add your code here\n",
    "\n",
    "# plot\n",
    "pdf(here(\"outputs\", \"basins_by_tabular_data.pdf\"), width = 11, height = 8.5)\n",
    "# add your code here\n",
    "\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SAVING DATA\n",
    "\n",
    "To save sf data to .shp files or other spatial file types, use the st_write() command. You'll notice it will also make all the other file extensions required for the .shp file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save nc_state_bounds_geom\n",
    "st_write(nc_state_bounds_geom, here(\"outputs\", \"nc_boundary.shp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look in your output directory to make sure your shp file is there!\n",
    "\n",
    "**Activity**\n",
    "\n",
    "Try saving another spatial dataset you created in Sections 3.1 or 3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use st_write(<variable name>, <file path.shp>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. EXTRA FEATURES & RESOURCES\n",
    "\n",
    "### 5.1 Other Interesting Spatial Packages\n",
    "\n",
    "**ggsn package**\n",
    "\n",
    "I haven't played around with adding compass roses, scale bars, and all these other important map elements. While not reproducible (I admit!), I will typically export to PDF and then do my edits in Inkscape (think open-source Adobe Illustrator). If you're really wanting to do this in a reproducible way, looks like you can use the [ggsn package](http://oswaldosantos.github.io/ggsn/) in R.\n",
    "\n",
    "**raster package**\n",
    "\n",
    "I definitely recommend using the raster package if you have to do any raster spatial data analysis. However, be warned that this package is currently not very friendly with tidyverse packages.\n",
    "\n",
    "**parallel and doParallel packages**\n",
    "\n",
    "If you have a big spatial dataset you might need to implement parallel computing. You can use these packages to do that.\n",
    "\n",
    "**tmap package**\n",
    "\n",
    "This package is great package for making maps. I didn't have enough time to cover it but I recommend checking it out. More information [here](https://github.com/mtennekes/tmap).\n",
    "\n",
    "**leaflet and mapview packages**\n",
    "\n",
    "You can use these packages to make your maps interactive. See more information about leaflet [here](https://rstudio.github.io/leaflet/) and about mapview [here](https://r-spatial.github.io/mapview/). Notably, the leaflet package only works with vector spatial data while mapview can be used for displaying both vector and raster data.\n",
    "\n",
    "### 5.2 Referece Materials\n",
    "\n",
    "Some good places to start looking for help with the sf package include the [rspatial website](https://cengel.github.io/R-spatial/) and the [sf package vignettes](https://r-spatial.github.io/sf/articles/sf1.html). I've listed out some other reference materials too.\n",
    "\n",
    "#### 5.2.1 Books & Blogs\n",
    "\n",
    "* [Geocomputation with R by Lovelace et al. - Open Online Book](https://bookdown.org/robinlovelace/geocompr/)\n",
    "* [Applied Spatial Data Analysis with R by Bivand et al. - Book](https://www.springer.com/gp/book/9781461476177)\n",
    "* [Ecological Mdels and Data in R by Bolker - Book](https://www.amazon.com/Ecological-Models-Data-Benjamin-Bolker/dp/0691125228)\n",
    "* [Spatial Data Analysis in Ecology and Agriculture Using R by Plant - Book](https://www.crcpress.com/Spatial-Data-Analysis-in-Ecology-and-Agriculture-Using-R-Second-Edition/Plant/p/book/9780815392750)\n",
    "* [sf geometrical operations - Blog post](http://rpubs.com/sogletr/sf-ops)\n",
    "* [R-Spatial Blog on ggplot2 and sf](https://www.r-spatial.org/r/2018/10/25/ggplot2-sf.html)\n",
    "* [R-Spatial-Ladies GitHub Reference List](https://github.com/rspatialladies/rspatial-resources)\n",
    "* So many more...\n",
    "\n",
    "#### 5.2.2 Cheatsheet(s)\n",
    "\n",
    "I've included a copy of the sf package cheatsheet in the project folder. I'd recommend printing it off and keeping it close-by for easy reference. You can find a number of cheatsheets for other tidyverse packages [here](https://rstudio.com/resources/cheatsheets/)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
